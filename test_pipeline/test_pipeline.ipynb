{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b3bfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rama/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU acceleration available: 0\n",
      "Iterating through scene_id, image_id combinations:\n",
      "============================================================\n",
      "\n",
      "Group 1: Scene 000000, Image 000000\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rama/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/rama/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 2: Scene 000000, Image 000001\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 3: Scene 000000, Image 000002\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 4: Scene 000000, Image 000003\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 5: Scene 000000, Image 000004\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 6: Scene 000000, Image 000005\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 7: Scene 000000, Image 000006\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 8: Scene 000000, Image 000007\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 9: Scene 000000, Image 000008\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 10: Scene 000000, Image 000009\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 11: Scene 000000, Image 000010\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 12: Scene 000000, Image 000011\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 13: Scene 000000, Image 000012\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 14: Scene 000000, Image 000013\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 15: Scene 000000, Image 000014\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 16: Scene 000000, Image 000015\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 17: Scene 000000, Image 000016\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 18: Scene 000000, Image 000017\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "\n",
      "Group 19: Scene 000000, Image 000018\n",
      "Number of cameras: 4\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/rama/bpc_ws/bpc/utilities/test_dataset.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m processor \u001b[38;5;241m=\u001b[39m SceneImageGroupProcessor(csv_file_path)\n\u001b[0;32m---> 67\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate_by_scene_image_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m, in \u001b[0;36mSceneImageGroupProcessor.iterate_by_scene_image_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m40\u001b[39m)\n\u001b[1;32m     44\u001b[0m scene_info \u001b[38;5;241m=\u001b[39m process_scene_data(scene_data\u001b[38;5;241m=\u001b[39mcamera_rows)\n\u001b[0;32m---> 45\u001b[0m \u001b[43mscene_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m scene_info\u001b[38;5;241m.\u001b[39mconsolidate_detections()\n\u001b[1;32m     48\u001b[0m compare_result \u001b[38;5;241m=\u001b[39m scene_info\u001b[38;5;241m.\u001b[39mdo_feature_matchings()\n",
      "File \u001b[0;32m~/bpc_ws/bpc/test_pipeline/process_scene_data.py:71\u001b[0m, in \u001b[0;36mprocess_scene_data.mask_objects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m     detection_json \u001b[38;5;241m=\u001b[39m infer(cam_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_image_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], maskrcnn_model_path, maskrcnn_output_path,  maskrcnn_category_txt_path, maskrcnn_confidence_threshold, visualize_and_save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaskrcnn_visualization_and_save\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     69\u001b[0m     cam_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetection_json\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m detection_json\n\u001b[0;32m---> 71\u001b[0m     cam_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetection_json\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43madd_3d_centers_to_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcam_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcam_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcam_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdetection_json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdepth_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcam_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdepth_image_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_radius\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscene_data\n",
      "File \u001b[0;32m~/bpc_ws/bpc/test_pipeline/update_detection_json.py:133\u001b[0m, in \u001b[0;36madd_3d_centers_to_json\u001b[0;34m(cam_row, json_data, depth_path, search_radius)\u001b[0m\n\u001b[1;32m    130\u001b[0m depth_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(cam_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscene_depth_scale\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Try to find valid 3D point\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m point_3d, used_pixel \u001b[38;5;241m=\u001b[39m \u001b[43mfind_valid_neighbor_pixel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_radius\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m point_3d \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# Convert to regular Python list for JSON serialization\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     center_3d \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(point_3d[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mfloat\u001b[39m(point_3d[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28mfloat\u001b[39m(point_3d[\u001b[38;5;241m2\u001b[39m])]\n",
      "File \u001b[0;32m~/bpc_ws/bpc/test_pipeline/update_detection_json.py:17\u001b[0m, in \u001b[0;36mfind_valid_neighbor_pixel\u001b[0;34m(center_u, center_v, depth_path, k_matrix, depth_scale, search_radius)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"Find a valid neighboring pixel if the center pixel has invalid depth.\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Try center pixel first\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m point_3d \u001b[38;5;241m=\u001b[39m \u001b[43mpixel_to_3d_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenter_u\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(point_3d)):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m point_3d, (center_u, center_v)\n",
      "File \u001b[0;32m~/bpc_ws/bpc/test_pipeline/pxl_to_point.py:157\u001b[0m, in \u001b[0;36mpixel_to_3d_point\u001b[0;34m(u, v, depth_path, k_matrix, depth_scale, return_color, rgb_path)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m points[\u001b[38;5;241m0\u001b[39m], colors[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 157\u001b[0m     points \u001b[38;5;241m=\u001b[39m \u001b[43mpixels_to_3d_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_scale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m points[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/bpc_ws/bpc/test_pipeline/pxl_to_point.py:44\u001b[0m, in \u001b[0;36mpixels_to_3d_points\u001b[0;34m(pixel_indices, depth_path, k_matrix, depth_scale, return_colors, rgb_path)\u001b[0m\n\u001b[1;32m     41\u001b[0m cy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(k_matrix[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Load depth image\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m depth_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMREAD_ANYDEPTH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# print(\"Depth image type: \", depth_img.dtype)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# print(depth_img.min(), depth_img.max())\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth_img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from process_scene_data import process_scene_data\n",
    "import cv2\n",
    "\n",
    "\n",
    "class SceneImageGroupProcessor:\n",
    "    def __init__(self, csv_file_path):\n",
    "        self.csv_file_path = csv_file_path\n",
    "    \n",
    "    def iterate_by_scene_image_groups(self):\n",
    "        \"\"\"\n",
    "        Iterate through CSV grouped by (scene_id, image_id) combinations.\n",
    "        For each group, process all camera rows together.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Dictionary to group rows by (scene_id, image_id)\n",
    "        grouped_data = defaultdict(list)\n",
    "\n",
    "        k = None\n",
    "        \n",
    "        try:\n",
    "            # First pass: Read and group the data\n",
    "            with open(self.csv_file_path, 'r', newline='', encoding='utf-8') as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                \n",
    "                for row in reader:\n",
    "                    scene_id = row['scene_id']\n",
    "                    image_id = row['image_id']\n",
    "                    key = (scene_id, image_id)\n",
    "                    grouped_data[key].append(row)\n",
    "            \n",
    "            # Second pass: Iterate through each group\n",
    "            print(\"Iterating through scene_id, image_id combinations:\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            for group_num, ((scene_id, image_id), camera_rows) in enumerate(grouped_data.items(), start=1):\n",
    "                print(f\"\\nGroup {group_num}: Scene {scene_id}, Image {image_id}\")\n",
    "                print(f\"Number of cameras: {len(camera_rows)}\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "                scene_info = process_scene_data(scene_data=camera_rows)\n",
    "                scene_info.mask_objects()\n",
    "                scene_info.consolidate_detections()\n",
    "\n",
    "                compare_result = scene_info.do_feature_matchings()\n",
    "                compare_result['visualization'].show()\n",
    "\n",
    "                cv2.waitKey(0)     \n",
    "                \n",
    "\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Could not find the file '{self.csv_file_path}'\")\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Column {e} not found in the CSV file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV file: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = \"/home/rama/bpc_ws/bpc/utilities/test_dataset.csv\"\n",
    "    \n",
    "    processor = SceneImageGroupProcessor(csv_file_path)\n",
    "    processor.iterate_by_scene_image_groups()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
